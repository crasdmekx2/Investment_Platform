name: Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

jobs:
  backend-tests:
    name: Backend Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: timescale/timescaledb:latest-pg15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: investment_platform_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Set up test database environment
        env:
          DB_HOST: localhost
          DB_PORT: 5432
          DB_NAME: investment_platform_test
          DB_USER: postgres
          DB_PASSWORD: postgres
        run: |
          # Wait for database to be ready
          until pg_isready -h localhost -p 5432 -U postgres; do
            echo "Waiting for database..."
            sleep 2
          done

      - name: Run backend tests with coverage
        env:
          DB_HOST: localhost
          DB_PORT: 5432
          DB_NAME: investment_platform_test
          DB_USER: postgres
          DB_PASSWORD: postgres
        run: |
          pytest \
            --cov=src/investment_platform \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term \
            --junit-xml=junit-backend.xml \
            -v

      - name: Upload coverage reports
        uses: codecov/codecov-action@v4
        if: always()
        with:
          file: ./coverage.xml
          flags: backend
          name: backend-coverage
          fail_ci_if_error: false

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: backend-test-results
          path: |
            junit-backend.xml
            htmlcov/
            coverage.xml

      - name: Check coverage threshold
        run: |
          # Extract coverage percentage from coverage report
          python -c "
          import xml.etree.ElementTree as ET
          try:
              tree = ET.parse('coverage.xml')
              root = tree.getroot()
              line_rate = float(root.attrib.get('line-rate', '0'))
              coverage_pct = line_rate * 100
              print(f'Coverage: {coverage_pct:.1f}%')
              if coverage_pct < 80:
                  print(f'âš ï¸ Coverage is {coverage_pct:.1f}%, which is below the 80% target')
                  print('This is a warning, not a failure')
              else:
                  print(f'âœ… Coverage is {coverage_pct:.1f}%, meeting the 80% target')
          except Exception as e:
              print(f'Could not parse coverage report: {e}')
          "

      - name: Create GitHub Issues for Test Failures
        if: failure() && github.event_name == 'push'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const { execSync } = require('child_process');
            
            // Function to classify severity based on test name and file
            function classifySeverity(testFile, testName) {
              const criticalKeywords = ['security', 'financial', 'transaction', 'data_integrity', 'payment'];
              const highKeywords = ['api', 'router', 'service', 'endpoint', 'database', 'scheduler'];
              
              const testPath = (testFile + ' ' + testName).toLowerCase();
              
              if (criticalKeywords.some(keyword => testPath.includes(keyword))) {
                return 'Critical';
              } else if (highKeywords.some(keyword => testPath.includes(keyword))) {
                return 'High';
              } else if (testPath.includes('e2e') || testPath.includes('integration')) {
                return 'High';
              } else {
                return 'Medium';
              }
            }
            
            // Function to check if issue already exists
            async function issueExists(octokit, owner, repo, testIdentifier) {
              const searchQuery = `repo:${owner}/${repo} is:issue is:open "${testIdentifier}"`;
              try {
                const { data } = await octokit.rest.search.issuesAndPullRequests({
                  q: searchQuery
                });
                return data.items.length > 0;
              } catch (error) {
                console.log(`Error checking for existing issue: ${error.message}`);
                return false;
              }
            }
            
            // Parse JUnit XML and create issues
            async function createIssuesFromJUnit() {
              const junitFile = 'junit-backend.xml';
              
              if (!fs.existsSync(junitFile)) {
                console.log('No JUnit XML file found, skipping issue creation');
                return;
              }
              
              const xmlContent = fs.readFileSync(junitFile, 'utf8');
              const { XMLParser } = require('fast-xml-parser');
              const parser = new XMLParser({ ignoreAttributes: false });
              
              let testResults;
              try {
                testResults = parser.parse(xmlContent);
              } catch (error) {
                console.log(`Error parsing JUnit XML: ${error.message}`);
                return;
              }
              
              const testsuites = testResults.testsuites || {};
              const testsuite = testsuites.testsuite || {};
              const testcases = Array.isArray(testsuite.testcase) 
                ? testsuite.testcase 
                : (testsuite.testcase ? [testsuite.testcase] : []);
              
              const failedTests = testcases.filter(tc => tc.failure || tc.error);
              
              if (failedTests.length === 0) {
                console.log('No failed tests found in JUnit XML');
                return;
              }
              
              console.log(`Found ${failedTests.length} failed test(s)`);
              
              const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
              const commitSha = process.env.GITHUB_SHA;
              const commitUrl = `https://github.com/${owner}/${repo}/commit/${commitSha}`;
              const workflowRunUrl = `https://github.com/${owner}/${repo}/actions/runs/${process.env.GITHUB_RUN_ID}`;
              
              for (const test of failedTests) {
                const testName = test['@_name'] || 'Unknown Test';
                const testClass = test['@_classname'] || 'Unknown Class';
                const testFile = test['@_classname'] ? test['@_classname'].replace(/\./g, '/') + '.py' : 'unknown';
                const failure = test.failure || test.error || {};
                const errorMessage = typeof failure === 'string' ? failure : (failure['#text'] || failure['@_message'] || 'No error message');
                const errorType = typeof failure === 'string' ? 'Error' : (failure['@_type'] || 'Error');
                
                const testIdentifier = `${testClass}::${testName}`;
                const severity = classifySeverity(testFile, testName);
                
                // Check if issue already exists
                const exists = await issueExists(octokit, owner, repo, testIdentifier);
                if (exists) {
                  console.log(`Issue for ${testIdentifier} already exists, skipping`);
                  continue;
                }
                
                // Create issue title
                const title = `[${severity}] Test Failure: ${testIdentifier}`;
                
                // Create issue body
                const body = `## Description
                
Test failure detected in CI/CD pipeline. This test is failing and needs investigation.

## Test File Reference
- **File:** \`${testFile}\`
- **Test:** \`${testIdentifier}\`
- **Test Class:** \`${testClass}\`
- **Test Name:** \`${testName}\`

## Steps to Reproduce
1. Run the test locally: \`pytest ${testFile}::${testClass}::${testName} -v\`
2. Or check the CI/CD logs for detailed output

## Expected Behavior
The test should pass successfully.

## Actual Behavior
The test is failing with the following error:

## Error Message
\`\`\`
${errorType}: ${errorMessage.substring(0, 1000)}
\`\`\`

## Severity
**${severity}** - ${severity === 'Critical' ? 'Blocks critical functionality' : severity === 'High' ? 'Blocks important functionality' : 'Affects non-critical functionality'}

## Additional Context
- **CI/CD Run:** ${workflowRunUrl}
- **Commit:** ${commitUrl}
- **Branch:** ${process.env.GITHUB_REF}
- **Workflow:** ${process.env.GITHUB_WORKFLOW}

## Recommended Actions
1. Reproduce the failure locally
2. Investigate the root cause
3. Fix the issue
4. Verify the fix with the test
5. Update this issue when resolved

## Related Issues
- Related to test failures in CI/CD
- See [Test Failure Workflow](https://github.com/${owner}/${repo}/blob/main/docs/TEST_FAILURE_WORKFLOW.md) for handling process
`;
                
                try {
                  const { data: issue } = await octokit.rest.issues.create({
                    owner,
                    repo,
                    title,
                    body,
                    labels: ['test-failure', `severity-${severity.toLowerCase()}`, 'ci/cd', 'backend']
                  });
                  
                  console.log(`Created issue #${issue.number} for ${testIdentifier}`);
                } catch (error) {
                  console.log(`Error creating issue for ${testIdentifier}: ${error.message}`);
                }
              }
            }
            
            // Install required package
            try {
              execSync('npm install fast-xml-parser --no-save', { stdio: 'inherit' });
            } catch (error) {
              console.log('Note: fast-xml-parser may already be installed or npm not available');
            }
            
            await createIssuesFromJUnit();

  frontend-tests:
    name: Frontend Tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        working-directory: frontend
        run: npm ci

      - name: Run frontend tests with coverage
        working-directory: frontend
        run: |
          npm run test:coverage -- --reporter=verbose --reporter=junit --outputFile=../junit-frontend.xml || true

      - name: Upload coverage reports
        uses: codecov/codecov-action@v4
        if: always()
        with:
          file: ./frontend/coverage/coverage-final.json
          flags: frontend
          name: frontend-coverage
          fail_ci_if_error: false

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: frontend-test-results
          path: |
            junit-frontend.xml
            frontend/coverage/

      - name: Create GitHub Issues for Test Failures
        if: failure() && github.event_name == 'push'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const { execSync } = require('child_process');
            
            // Function to classify severity based on test name and file
            function classifySeverity(testFile, testName) {
              const criticalKeywords = ['security', 'financial', 'transaction', 'data_integrity', 'payment'];
              const highKeywords = ['api', 'router', 'service', 'endpoint', 'component', 'hook', 'integration'];
              
              const testPath = (testFile + ' ' + testName).toLowerCase();
              
              if (criticalKeywords.some(keyword => testPath.includes(keyword))) {
                return 'Critical';
              } else if (highKeywords.some(keyword => testPath.includes(keyword))) {
                return 'High';
              } else if (testPath.includes('e2e') || testPath.includes('integration')) {
                return 'High';
              } else {
                return 'Medium';
              }
            }
            
            // Function to check if issue already exists
            async function issueExists(octokit, owner, repo, testIdentifier) {
              const searchQuery = `repo:${owner}/${repo} is:issue is:open "${testIdentifier}"`;
              try {
                const { data } = await octokit.rest.search.issuesAndPullRequests({
                  q: searchQuery
                });
                return data.items.length > 0;
              } catch (error) {
                console.log(`Error checking for existing issue: ${error.message}`);
                return false;
              }
            }
            
            // Parse JUnit XML and create issues
            async function createIssuesFromJUnit() {
              const junitFile = 'junit-frontend.xml';
              
              if (!fs.existsSync(junitFile)) {
                console.log('No JUnit XML file found, skipping issue creation');
                return;
              }
              
              const xmlContent = fs.readFileSync(junitFile, 'utf8');
              const { XMLParser } = require('fast-xml-parser');
              const parser = new XMLParser({ ignoreAttributes: false });
              
              let testResults;
              try {
                testResults = parser.parse(xmlContent);
              } catch (error) {
                console.log(`Error parsing JUnit XML: ${error.message}`);
                return;
              }
              
              const testsuites = testResults.testsuites || {};
              const testsuite = testsuites.testsuite || {};
              const testcases = Array.isArray(testsuite.testcase) 
                ? testsuite.testcase 
                : (testsuite.testcase ? [testsuite.testcase] : []);
              
              const failedTests = testcases.filter(tc => tc.failure || tc.error);
              
              if (failedTests.length === 0) {
                console.log('No failed tests found in JUnit XML');
                return;
              }
              
              console.log(`Found ${failedTests.length} failed test(s)`);
              
              const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
              const commitSha = process.env.GITHUB_SHA;
              const commitUrl = `https://github.com/${owner}/${repo}/commit/${commitSha}`;
              const workflowRunUrl = `https://github.com/${owner}/${repo}/actions/runs/${process.env.GITHUB_RUN_ID}`;
              
              for (const test of failedTests) {
                const testName = test['@_name'] || 'Unknown Test';
                const testClass = test['@_classname'] || testName;
                const testFile = test['@_classname'] ? test['@_classname'].replace(/\./g, '/') + '.tsx' : 'unknown';
                const failure = test.failure || test.error || {};
                const errorMessage = typeof failure === 'string' ? failure : (failure['#text'] || failure['@_message'] || 'No error message');
                const errorType = typeof failure === 'string' ? 'Error' : (failure['@_type'] || 'Error');
                
                const testIdentifier = `${testClass}::${testName}`;
                const severity = classifySeverity(testFile, testName);
                
                // Check if issue already exists
                const exists = await issueExists(octokit, owner, repo, testIdentifier);
                if (exists) {
                  console.log(`Issue for ${testIdentifier} already exists, skipping`);
                  continue;
                }
                
                // Create issue title
                const title = `[${severity}] Test Failure: ${testIdentifier}`;
                
                // Create issue body
                const body = `## Description
                
Test failure detected in CI/CD pipeline. This test is failing and needs investigation.

## Test File Reference
- **File:** \`${testFile}\`
- **Test:** \`${testIdentifier}\`
- **Test Class:** \`${testClass}\`
- **Test Name:** \`${testName}\`

## Steps to Reproduce
1. Run the test locally: \`npm test -- ${testFile} -t "${testName}"\`
2. Or check the CI/CD logs for detailed output

## Expected Behavior
The test should pass successfully.

## Actual Behavior
The test is failing with the following error:

## Error Message
\`\`\`
${errorType}: ${errorMessage.substring(0, 1000)}
\`\`\`

## Severity
**${severity}** - ${severity === 'Critical' ? 'Blocks critical functionality' : severity === 'High' ? 'Blocks important functionality' : 'Affects non-critical functionality'}

## Additional Context
- **CI/CD Run:** ${workflowRunUrl}
- **Commit:** ${commitUrl}
- **Branch:** ${process.env.GITHUB_REF}
- **Workflow:** ${process.env.GITHUB_WORKFLOW}

## Recommended Actions
1. Reproduce the failure locally
2. Investigate the root cause
3. Fix the issue
4. Verify the fix with the test
5. Update this issue when resolved

## Related Issues
- Related to test failures in CI/CD
- See [Test Failure Workflow](https://github.com/${owner}/${repo}/blob/main/docs/TEST_FAILURE_WORKFLOW.md) for handling process
`;
                
                try {
                  const { data: issue } = await octokit.rest.issues.create({
                    owner,
                    repo,
                    title,
                    body,
                    labels: ['test-failure', `severity-${severity.toLowerCase()}`, 'ci/cd', 'frontend']
                  });
                  
                  console.log(`Created issue #${issue.number} for ${testIdentifier}`);
                } catch (error) {
                  console.log(`Error creating issue for ${testIdentifier}: ${error.message}`);
                }
              }
            }
            
            // Install required package
            try {
              execSync('npm install fast-xml-parser --no-save', { stdio: 'inherit' });
            } catch (error) {
              console.log('Note: fast-xml-parser may already be installed or npm not available');
            }
            
            await createIssuesFromJUnit();

  lint-and-format:
    name: Lint and Format Check
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt

      - name: Run Black formatter check
        run: |
          black --check --diff src/ tests/ || echo "Black check failed (non-blocking)"

      - name: Run Flake8 linter
        run: |
          flake8 src/ tests/ --max-line-length=100 --extend-ignore=E203,E266,E501,W503 || echo "Flake8 check failed (non-blocking)"

      - name: Run mypy type checker
        run: |
          mypy src/investment_platform --ignore-missing-imports || echo "mypy check failed (non-blocking)"

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install frontend dependencies
        working-directory: frontend
        run: npm ci

      - name: Run ESLint
        working-directory: frontend
        run: npm run lint || echo "ESLint check failed (non-blocking)"

      - name: Check Prettier formatting
        working-directory: frontend
        run: npm run format:check || echo "Prettier check failed (non-blocking)"

  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    # Only run E2E tests on main branch or when explicitly requested
    if: github.ref == 'refs/heads/main' || github.event_name == 'pull_request'

    services:
      postgres:
        image: timescale/timescaledb:latest-pg15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: investment_platform_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install frontend dependencies
        working-directory: frontend
        run: npm ci

      - name: Install Playwright browsers
        working-directory: frontend
        run: npx playwright install --with-deps

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Start API server
        env:
          DB_HOST: localhost
          DB_PORT: 5432
          DB_NAME: investment_platform_test
          DB_USER: postgres
          DB_PASSWORD: postgres
          ENABLE_EMBEDDED_SCHEDULER: "false"
        run: |
          # Start API server in background
          python -m investment_platform.api.main &
          sleep 5
          # Wait for server to be ready
          until curl -f http://localhost:8000/api/health; do
            echo "Waiting for API server..."
            sleep 2
          done

      - name: Run E2E tests
        working-directory: frontend
        env:
          VITE_API_URL: http://localhost:8000
        run: |
          npm run test:e2e || echo "E2E tests failed or skipped"

      - name: Upload E2E test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results
          path: |
            frontend/test-results/
            frontend/playwright-report/

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [backend-tests, frontend-tests, lint-and-format]
    if: always()

    steps:
      - name: Check test results
        run: |
          echo "## Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Backend tests: ${{ needs.backend-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Frontend tests: ${{ needs.frontend-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Lint and format: ${{ needs.lint-and-format.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.backend-tests.result }}" != "success" ] || \
             [ "${{ needs.frontend-tests.result }}" != "success" ] || \
             [ "${{ needs.lint-and-format.result }}" != "success" ]; then
            echo "âŒ Some tests failed. Please check the logs above." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "ðŸ“‹ GitHub issues have been automatically created for test failures (if any)." >> $GITHUB_STEP_SUMMARY
            echo "See the Issues tab to review and track them." >> $GITHUB_STEP_SUMMARY
            exit 1
          else
            echo "âœ… All tests passed!" >> $GITHUB_STEP_SUMMARY
          fi
